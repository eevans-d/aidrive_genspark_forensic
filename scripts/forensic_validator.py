#!/usr/bin/env python3
"""
HERRAMIENTA FORENSE AVANZADA - VALIDADOR DE METODOLOGÃA
Valida que los anÃ¡lisis forenses cumplan con los principios fundamentales
"""

import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import argparse


class ForensicValidator:
    """Validador de metodologÃ­a forense para anÃ¡lisis tÃ©cnicos"""
    
    def __init__(self, repository_path: str):
        self.repo_path = Path(repository_path)
        self.forensic_principles = {
            'archivo_linea_citations': r'`[^`]+:\d+(-\d+)?`',
            'risk_markers': r'(RIESGO|RISK)\s+(CRÃTICO|ALTO|MEDIO|HIGH|MEDIUM|CRITICAL)',
            'no_evidenciado': r'NO\s+EVIDENCIADO',
            'passive_mode': r'(modificar|cambiar|editar|modify|change|edit)',
            'verification_commands': r'```bash\n.*?```'
        }
        
    def validate_forensic_analysis(self, analysis_file: Path) -> Dict[str, any]:
        """Valida un archivo de anÃ¡lisis forense contra los principios"""
        
        if not analysis_file.exists():
            return {'error': f'Archivo no encontrado: {analysis_file}'}
            
        content = analysis_file.read_text(encoding='utf-8')
        
        results = {
            'file': str(analysis_file),
            'total_lines': len(content.split('\n')),
            'citations_count': 0,
            'risk_markers_count': 0,
            'no_evidenciado_count': 0,
            'passive_violations': [],
            'verification_commands': 0,
            'compliance_score': 0.0,
            'recommendations': []
        }
        
        # Validar citas archivo:lÃ­nea
        citations = re.findall(self.forensic_principles['archivo_linea_citations'], content)
        results['citations_count'] = len(citations)
        
        # Validar marcadores de riesgo
        risk_markers = re.findall(self.forensic_principles['risk_markers'], content, re.IGNORECASE)
        results['risk_markers_count'] = len(risk_markers)
        
        # Validar marcadores "NO EVIDENCIADO"
        no_evidenciado = re.findall(self.forensic_principles['no_evidenciado'], content, re.IGNORECASE)
        results['no_evidenciado_count'] = len(no_evidenciado)
        
        # Detectar violaciones de modo pasivo
        passive_violations = re.findall(self.forensic_principles['passive_mode'], content, re.IGNORECASE)
        results['passive_violations'] = passive_violations[:5]  # Limitar a 5 ejemplos
        
        # Contar comandos de verificaciÃ³n
        verification_commands = re.findall(self.forensic_principles['verification_commands'], content, re.DOTALL)
        results['verification_commands'] = len(verification_commands)
        
        # Calcular score de compliance
        results['compliance_score'] = self._calculate_compliance_score(results)
        
        # Generar recomendaciones
        results['recommendations'] = self._generate_recommendations(results)
        
        return results
    
    def _calculate_compliance_score(self, results: Dict) -> float:
        """Calcula score de compliance forense (0-100)"""
        
        score = 0.0
        
        # Citas archivo:lÃ­nea (40% del score)
        if results['citations_count'] > 0:
            score += min(40, results['citations_count'] * 2)
        
        # Marcadores de riesgo (20% del score)
        if results['risk_markers_count'] > 0:
            score += min(20, results['risk_markers_count'] * 4)
        
        # NO EVIDENCIADO (15% del score)
        if results['no_evidenciado_count'] > 0:
            score += min(15, results['no_evidenciado_count'] * 3)
        
        # Comandos de verificaciÃ³n (15% del score)
        if results['verification_commands'] > 0:
            score += min(15, results['verification_commands'] * 3)
        
        # PenalizaciÃ³n por violaciones de modo pasivo (hasta -30)
        passive_penalty = min(30, len(results['passive_violations']) * 10)
        score -= passive_penalty
        
        # Bonus por integridad metodolÃ³gica (10%)
        if (results['citations_count'] >= 10 and 
            results['risk_markers_count'] >= 3 and 
            len(results['passive_violations']) == 0):
            score += 10
        
        return max(0.0, min(100.0, score))
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """Genera recomendaciones para mejorar compliance forense"""
        
        recommendations = []
        
        if results['citations_count'] < 10:
            recommendations.append(
                f"âŒ CRÃTICO: Solo {results['citations_count']} citas archivo:lÃ­nea detectadas. "
                "MÃ­nimo requerido: 10+ para anÃ¡lisis forense vÃ¡lido."
            )
        
        if results['risk_markers_count'] < 3:
            recommendations.append(
                f"âš ï¸ ALTO: Solo {results['risk_markers_count']} marcadores de riesgo. "
                "AnÃ¡lisis forense debe identificar mÃ­nimo 3 riesgos con severidad."
            )
        
        if results['no_evidenciado_count'] == 0:
            recommendations.append(
                "âš ï¸ MEDIO: Sin marcadores 'NO EVIDENCIADO'. "
                "AnÃ¡lisis forense debe reconocer explÃ­citamente limitaciones."
            )
        
        if len(results['passive_violations']) > 0:
            recommendations.append(
                f"âŒ CRÃTICO: {len(results['passive_violations'])} violaciones de modo pasivo detectadas. "
                "El anÃ¡lisis NO debe sugerir modificaciones de cÃ³digo."
            )
        
        if results['verification_commands'] < 5:
            recommendations.append(
                f"âš ï¸ MEDIO: Solo {results['verification_commands']} comandos de verificaciÃ³n. "
                "Incluir mÃ­nimo 5 comandos ejecutables para validaciÃ³n."
            )
        
        if results['compliance_score'] >= 90:
            recommendations.append("âœ… EXCELENTE: MetodologÃ­a forense aplicada correctamente.")
        elif results['compliance_score'] >= 70:
            recommendations.append("âœ… BUENO: MetodologÃ­a forense en gran parte correcta.")
        else:
            recommendations.append("âŒ DEFICIENTE: MetodologÃ­a forense requiere mejoras significativas.")
            
        return recommendations
    
    def validate_all_forensic_files(self) -> Dict[str, any]:
        """Valida todos los archivos de anÃ¡lisis forense en el repositorio"""
        
        forensic_files = list(self.repo_path.glob("**/EJEMPLO_ANALISIS_FORENSE_*.md"))
        forensic_files.extend(self.repo_path.glob("**/ANALISIS_FORENSE_*.md"))
        
        if not forensic_files:
            return {
                'error': 'No se encontraron archivos de anÃ¡lisis forense',
                'searched_patterns': ['**/EJEMPLO_ANALISIS_FORENSE_*.md', '**/ANALISIS_FORENSE_*.md']
            }
        
        results = {
            'total_files': len(forensic_files),
            'files_analyzed': [],
            'overall_compliance': 0.0,
            'summary': {
                'excellent': 0,  # >= 90
                'good': 0,       # >= 70
                'poor': 0        # < 70
            }
        }
        
        total_score = 0.0
        
        for file_path in forensic_files:
            file_result = self.validate_forensic_analysis(file_path)
            results['files_analyzed'].append(file_result)
            
            score = file_result.get('compliance_score', 0.0)
            total_score += score
            
            if score >= 90:
                results['summary']['excellent'] += 1
            elif score >= 70:
                results['summary']['good'] += 1
            else:
                results['summary']['poor'] += 1
        
        results['overall_compliance'] = total_score / len(forensic_files) if forensic_files else 0.0
        
        return results
    
    def generate_compliance_report(self, output_file: Optional[Path] = None) -> str:
        """Genera reporte completo de compliance forense"""
        
        validation_results = self.validate_all_forensic_files()
        
        if 'error' in validation_results:
            return f"Error: {validation_results['error']}"
        
        report = []
        report.append("# ğŸ”¬ REPORTE DE COMPLIANCE FORENSE")
        report.append("## ValidaciÃ³n de MetodologÃ­a de AnÃ¡lisis Forense")
        report.append("")
        report.append(f"**ğŸ“… Fecha**: {os.popen('date').read().strip()}")
        report.append(f"**ğŸ“ Repositorio**: {self.repo_path.name}")
        report.append(f"**ğŸ“Š Archivos analizados**: {validation_results['total_files']}")
        report.append(f"**ğŸ¯ Compliance promedio**: {validation_results['overall_compliance']:.1f}%")
        report.append("")
        
        # Resumen ejecutivo
        report.append("## ğŸ“ˆ RESUMEN EJECUTIVO")
        report.append("")
        summary = validation_results['summary']
        report.append(f"- âœ… **Excelente** (â‰¥90%): {summary['excellent']} archivos")
        report.append(f"- âš ï¸ **Bueno** (â‰¥70%): {summary['good']} archivos")
        report.append(f"- âŒ **Deficiente** (<70%): {summary['poor']} archivos")
        report.append("")
        
        # AnÃ¡lisis detallado por archivo
        report.append("## ğŸ” ANÃLISIS DETALLADO")
        report.append("")
        
        for file_result in validation_results['files_analyzed']:
            file_name = Path(file_result['file']).name
            score = file_result['compliance_score']
            
            if score >= 90:
                status = "âœ… EXCELENTE"
            elif score >= 70:
                status = "âš ï¸ BUENO"
            else:
                status = "âŒ DEFICIENTE"
            
            report.append(f"### {file_name} - {status} ({score:.1f}%)")
            report.append("")
            report.append(f"- **Citas archivo:lÃ­nea**: {file_result['citations_count']}")
            report.append(f"- **Marcadores de riesgo**: {file_result['risk_markers_count']}")
            report.append(f"- **NO EVIDENCIADO**: {file_result['no_evidenciado_count']}")
            report.append(f"- **Comandos verificaciÃ³n**: {file_result['verification_commands']}")
            report.append(f"- **Violaciones modo pasivo**: {len(file_result['passive_violations'])}")
            report.append("")
            
            if file_result['recommendations']:
                report.append("**Recomendaciones:**")
                for rec in file_result['recommendations'][:3]:  # Top 3 recomendaciones
                    report.append(f"- {rec}")
                report.append("")
        
        # Recomendaciones generales
        report.append("## ğŸ¯ RECOMENDACIONES GENERALES")
        report.append("")
        
        if validation_results['overall_compliance'] >= 90:
            report.append("âœ… La metodologÃ­a forense se estÃ¡ aplicando correctamente en todo el repositorio.")
        elif validation_results['overall_compliance'] >= 70:
            report.append("âš ï¸ La metodologÃ­a forense se aplica bien pero requiere mejoras menores.")
        else:
            report.append("âŒ La metodologÃ­a forense requiere mejoras significativas.")
            report.append("")
            report.append("### Acciones prioritarias:")
            report.append("1. Incrementar citas `archivo:lÃ­nea` en anÃ¡lisis tÃ©cnicos")
            report.append("2. Identificar y clasificar mÃ¡s riesgos con severidad")
            report.append("3. Eliminar sugerencias de modificaciÃ³n de cÃ³digo")
            report.append("4. AÃ±adir mÃ¡s comandos de verificaciÃ³n ejecutables")
        
        report_text = "\n".join(report)
        
        if output_file:
            output_file.write_text(report_text, encoding='utf-8')
            
        return report_text


def main():
    parser = argparse.ArgumentParser(description='Validador de metodologÃ­a forense')
    parser.add_argument('repository', help='Ruta al repositorio a analizar')
    parser.add_argument('--output', '-o', help='Archivo de salida para el reporte')
    parser.add_argument('--file', '-f', help='Analizar archivo especÃ­fico')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.repository):
        print(f"Error: Repositorio no encontrado: {args.repository}")
        sys.exit(1)
    
    validator = ForensicValidator(args.repository)
    
    if args.file:
        # Analizar archivo especÃ­fico
        file_path = Path(args.file)
        if not file_path.is_absolute():
            file_path = Path(args.repository) / file_path
            
        result = validator.validate_forensic_analysis(file_path)
        
        print(f"ğŸ“„ Archivo: {result['file']}")
        print(f"ğŸ¯ Compliance Score: {result['compliance_score']:.1f}%")
        print(f"ğŸ“ Citas archivo:lÃ­nea: {result['citations_count']}")
        print(f"âš ï¸ Marcadores de riesgo: {result['risk_markers_count']}")
        print(f"âŒ Violaciones modo pasivo: {len(result['passive_violations'])}")
        print("")
        print("ğŸ” Recomendaciones:")
        for rec in result['recommendations']:
            print(f"  {rec}")
    else:
        # Generar reporte completo
        output_file = None
        if args.output:
            output_file = Path(args.output)
        
        report = validator.generate_compliance_report(output_file)
        print(report)
        
        if output_file:
            print(f"\nğŸ“„ Reporte guardado en: {output_file}")


if __name__ == "__main__":
    main()