# ğŸš€ Sistema Inventario Multi-Agente - GuÃ­a de Deployment

## ğŸ—ï¸ Arquitectura del Sistema

### Diagrama de Componentes (ETAPA 3 - Actualizado)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Users/Clients                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                        â”‚   NGINX     â”‚ Port 80/443
                        â”‚  TLS Ready  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Agente â”‚   Port 8001â”‚Dashboard â”‚ Port 8080â”‚ Metrics â”‚
    â”‚DepÃ³sito            â”‚          â”‚          â”‚Prometheus
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
    JWT â”‚                 API Key                   â”‚
    Authâ”‚              Authorization           X-API-Key
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
  â”‚  PostgreSQL    â”‚     â”‚   Redis   â”‚
  â”‚  Cifrado en    â”‚     â”‚   Cache   â”‚
  â”‚  Reposo (AES)  â”‚     â”‚           â”‚
  â”‚  + AuditorÃ­a   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Observability Stack                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Prometheus (9090)  â”€â”€TLSâ”€â”€â–¶ Alertmanager (9093)                â”‚
â”‚     â”‚                          â”‚                                 â”‚
â”‚     â”‚                      Slack/Email                           â”‚
â”‚  Scrape Metrics              Alerts                              â”‚
â”‚     â”‚                                                             â”‚
â”‚  â—€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Grafana (3000)                             â”‚
â”‚     â”‚                                                             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â–¶ Loki (3100) â”€â”€â–¶ Logs                               â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Security Layer                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  TLS Certificates    PostgreSQL Encryption    API Keys          â”‚
â”‚  (Mutual Auth)       (AES-256-CBC)            (Dashboard)       â”‚
â”‚                      pgcrypto + Audit         X-API-Key Header  â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos Seguro

```
1. CLIENTE REQUEST (HTTPS - TLS 1.2+)
   Client â”€TLSâ”€â–¶ Nginx â”€JWTâ”€â–¶ Dashboard â”€API Keyâ”€â–¶ Backend

2. BACKEND COMMUNICATION (MUTUAL TLS)
   Prometheus â”€mTLSâ”€â–¶ Alertmanager
   (certificado cliente + servidor validados)

3. BASE DE DATOS (CIFRADO EN REPOSO)
   Dashboard/Agentes â”€SQLâ”€â–¶ PostgreSQL
   Datos sensibles: decrypt_data() con clave maestra
   Acceso registrado: encrypted_data_access_log

4. OBSERVABILIDAD (SECURE SCRAPING)
   Prometheus â”€API Keyâ”€â–¶ Dashboard /metrics
   Grafana â”€datasourceâ”€â–¶ Prometheus (http://prometheus:9090)
   Logs: Promtail â”€pushâ”€â–¶ Loki â”€queryâ”€â–¶ Grafana
```

---

## ğŸ“‹ Componentes del Sistema

### Servicios Principales
- **AgenteDepÃ³sito** (Puerto 8001) - GestiÃ³n ACID de stock y productos
- **AgenteNegocio** (Puerto 8002) - OCR, pricing y reglas de negocio  
- **ML Service** (Puerto 8003) - Predicciones y machine learning
- **Dashboard Web** (Puerto 8080) - Interfaz de usuario principal
- **Nginx** (Puerto 80/443) - Reverse proxy y load balancer

### Infraestructura
- **PostgreSQL** (Puerto 5432) - Base de datos principal
- **Redis** (Puerto 6379) - Cache y sessions

---

## ğŸ› ï¸ InstalaciÃ³n y Deployment

### Prerrequisitos
```bash
# Docker & Docker Compose
sudo apt update
sudo apt install docker.io docker-compose
sudo usermod -aG docker $USER

# Verificar instalaciÃ³n
docker --version
docker-compose --version
```

### Deployment RÃ¡pido

1. **Clonar y configurar**:
```bash
git clone <repo-url>
cd inventario-retail

# Configurar environment
cp .env.production.template .env.production
nano .env.production  # Editar valores reales
```

2. **Desplegar sistema completo**:
```bash
./scripts/deploy.sh --up
```

3. **Verificar estado**:
```bash
./scripts/deploy.sh --status
```

### URLs del Sistema
- Dashboard Principal: http://localhost
- API DepÃ³sito: http://localhost/api/deposito/
- API Negocio: http://localhost/api/negocio/  
- API ML: http://localhost/api/ml/

---

## ğŸ”§ GestiÃ³n del Sistema

### Comandos Principales
```bash
# Verificar prerrequisitos
./scripts/deploy.sh --check

# Construir imÃ¡genes
./scripts/deploy.sh --build

# Levantar servicios
./scripts/deploy.sh --up

# Ver logs en tiempo real
./scripts/deploy.sh --logs

# Ver estado de servicios
./scripts/deploy.sh --status

# Reiniciar servicios
./scripts/deploy.sh --restart

# Detener servicios
./scripts/deploy.sh --down

# Backup de base de datos
./scripts/deploy.sh --backup

# Restaurar backup
./scripts/deploy.sh --restore backup_file.sql
```

### Monitoreo
```bash
# Ver logs especÃ­ficos
docker-compose -f docker-compose.production.yml logs -f agente-deposito
docker-compose -f docker-compose.production.yml logs -f dashboard

# Acceder a contenedores
docker exec -it agente_deposito bash
docker exec -it inventario_retail_db psql -U postgres inventario_retail

# Ver mÃ©tricas de recursos
docker stats
```

---

## âš™ï¸ ConfiguraciÃ³n de ProducciÃ³n

### Variables de Entorno CrÃ­ticas
```bash
# Seguridad
JWT_SECRET_KEY=<256-bit-random-key>
POSTGRES_PASSWORD=<secure-password>
DASHBOARD_API_KEY=<api-key>

# CORS (restrictivo en producciÃ³n)
CORS_ORIGINS=https://yourdomain.com,https://api.yourdomain.com

# Base de datos
DATABASE_URL=postgresql://user:pass@postgres:5432/inventario_retail
```

### SSL/HTTPS (ProducciÃ³n)
```bash
# Obtener certificados SSL
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d yourdomain.com

# El nginx.conf ya incluye configuraciÃ³n HTTPS
```

---

## ğŸ›¡ï¸ Seguridad

### AutenticaciÃ³n JWT
- Todos los endpoints API estÃ¡n protegidos con JWT
- Roles: `admin`, `deposito`, `negocio`, `ml_service`
- Tokens expiran en 8 horas (configurable)

### API Keys
- Dashboard API protegido con `DASHBOARD_API_KEY`
- Header requerido: `X-API-Key: <your-key>`

### CORS
- Configurado restrictivamente en producciÃ³n
- Solo orÃ­genes autorizados en `CORS_ORIGINS`

---

## ğŸ“Š Monitoreo y Observabilidad

### Health Checks
```bash
# Verificar salud de todos los servicios
curl http://localhost/health
curl http://localhost:8001/health  # Agente DepÃ³sito
curl http://localhost:8002/health  # Agente Negocio
curl http://localhost:8003/health  # ML Service
curl http://localhost:8080/health  # Dashboard
```

### Logs
- Logs centralizados en `./logs/`
- RotaciÃ³n automÃ¡tica diaria
- Formato JSON para parsing automÃ¡tico

### MÃ©tricas
- MÃ©tricas Prometheus en endpoints `/metrics`
- Grafana dashboard configurado (opcional)

---

## ï¿½ Observability Stack (ETAPA 3)

### Componentes del Stack

El sistema incluye un stack completo de observabilidad con:

- **Prometheus** (Puerto 9090) - RecolecciÃ³n y almacenamiento de mÃ©tricas
- **Grafana** (Puerto 3000) - VisualizaciÃ³n de mÃ©tricas y logs
- **Loki** (Puerto 3100) - AgregaciÃ³n de logs
- **Promtail** (Puerto 9080) - Recolector de logs Docker
- **Alertmanager** (Puerto 9093) - GestiÃ³n de alertas
- **Node Exporter** (Puerto 9100) - MÃ©tricas del sistema host
- **Postgres Exporter** (Puerto 9187) - MÃ©tricas de PostgreSQL
- **Redis Exporter** (Puerto 9121) - MÃ©tricas de Redis

### Deployment del Stack de Observability

**1. Verificar que servicios principales estÃ¡n corriendo:**
```bash
# Los servicios principales deben estar UP antes de desplegar observability
docker-compose -f docker-compose.production.yml ps
```

**2. Desplegar stack de observability:**
```bash
cd inventario-retail/observability

# Levantar todos los componentes
docker-compose -f docker-compose.observability.yml up -d

# Verificar que todos estÃ¡n UP
docker-compose -f docker-compose.observability.yml ps
```

**3. Verificar conectividad:**
```bash
# Verificar que Prometheus puede alcanzar targets
curl http://localhost:9090/-/healthy
# Esperado: "Prometheus is Healthy."

# Verificar Grafana estÃ¡ UP
curl http://localhost:3000/api/health
# Esperado: {"database":"ok"}

# Verificar Loki estÃ¡ listo
curl http://localhost:3100/ready
# Esperado: "ready"
```

### Acceso a Interfaces Web

**Grafana (Principal):**
- URL: http://localhost:3000
- Usuario: `admin`
- Password: `admin` (cambiar en primer acceso)
- Datasources: Pre-configuradas automÃ¡ticamente (Prometheus, Loki)

**Prometheus UI:**
- URL: http://localhost:9090
- Verificar targets: http://localhost:9090/targets
- Verificar alertas: http://localhost:9090/alerts

**Alertmanager:**
- URL: http://localhost:9093
- Ver alertas activas: http://localhost:9093/#/alerts

### Dashboards de Grafana

El sistema incluye 4 dashboards pre-configurados:

**1. System Overview** (`minimarket-system-overview`)
- Salud de los 4 servicios (UP/DOWN)
- Request rate por servicio
- Error rate % con thresholds
- P95 latency en milisegundos
- Uptime % de Ãºltima semana

**2. Business KPIs** (`minimarket-business-kpis`)
- Productos depositados por hora
- Alertas de stock crÃ­tico
- Ã“rdenes de compra generadas
- InflaciÃ³n calculada vs baseline
- Revenue proyectado vs real
- DistribuciÃ³n de productos por categorÃ­a
- Trending de Ã³rdenes (hourly)

**3. Performance** (`minimarket-performance`)
- CPU usage % por contenedor
- Memory usage % por contenedor
- Disk I/O (read/write) en Bps
- Network I/O (RX/TX) en Bps
- PostgreSQL connections activas vs max
- Redis cache hit rate %
- Redis clients y keys activos

**4. ML Service Monitor** (`minimarket-ml-service`)
- OCR processing time (P50/P95/P99)
- OCR timeout events por hora
- Price prediction accuracy %
- ML model drift score
- CPU/Memory del servicio ML
- Predictions & cache performance
- DistribuciÃ³n de modelos en uso
- ML/OCR errors por minuto

**Acceso a dashboards:**
```bash
# Abrir Grafana: http://localhost:3000
# Login: admin/admin
# Navegar a: Dashboards > Browse
# Folder: "MiniMarket"
# Seleccionar dashboard deseado
```

### ConfiguraciÃ³n de Alertmanager y Slack

**1. Configurar webhook de Slack:**
```bash
# Editar observability/alertmanager/alertmanager.yml
nano inventario-retail/observability/alertmanager/alertmanager.yml

# Reemplazar placeholder con webhook real:
receivers:
  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#minimarket-alerts'
        username: 'Prometheus AlertManager'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

**2. Aplicar cambios:**
```bash
# Reiniciar Alertmanager
docker-compose -f docker-compose.observability.yml restart alertmanager

# Verificar configuraciÃ³n
curl http://localhost:9093/api/v2/status
```

**3. Probar alertas manualmente:**
```bash
# Enviar alerta de prueba
curl -XPOST http://localhost:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "TestAlert",
      "severity": "warning"
    },
    "annotations": {
      "summary": "Test alert from Mini Market",
      "description": "This is a test alert to verify Slack integration"
    }
  }
]'

# Verificar que llegÃ³ a Slack en #minimarket-alerts
```

### Alertas Configuradas

El sistema incluye 15 alertas pre-configuradas:

**CRITICAL (5 alertas):**
- `ServiceDown` - Servicio no responde >2 minutos
- `HighErrorRate` - Tasa de errores >5% durante 5 minutos
- `DatabaseDown` - PostgreSQL no responde >1 minuto
- `DiskSpaceCritical` - Espacio en disco <10% durante 5 minutos
- `RedisDown` - Redis no responde >2 minutos

**HIGH (5 alertas):**
- `HighLatency` - P95 latency >300ms durante 10 minutos
- `MemoryPressure` - Uso de memoria >80% durante 10 minutos
- `CPUHigh` - CPU >70% durante 15 minutos
- `StockCritico` - >50 productos en stock crÃ­tico durante 15 minutos
- `OCRTimeoutSpike` - >10 timeouts de OCR por hora durante 10 minutos
- `CacheHitRateLow` - Redis cache hit rate <70% durante 15 minutos

**MEDIUM (5 alertas):**
- `SlowRequests` - P50 latency >200ms durante 20 minutos
- `InflacionAnomaly` - InflaciÃ³n difiere >5% del baseline durante 30 minutos
- `MLModelDrift` - Model drift score >0.15 durante 1 hora
- `LogVolumeSpike` - Volumen de logs aumenta >200% durante 15 minutos
- `DeploymentIssue` - Servicio reiniciado >3 veces en 10 minutos

**Ver alertas activas:**
```bash
# En Prometheus UI
http://localhost:9090/alerts

# O vÃ­a API
curl http://localhost:9090/api/v1/alerts | jq '.data.alerts[] | {alert: .labels.alertname, state: .state}'
```

### Testing del Stack de Observability

**1. Verificar Prometheus targets:**
```bash
# Abrir http://localhost:9090/targets
# Todos deben estar en estado "UP" (verde)

# Targets esperados:
# - agente_deposito (8001)
# - agente_negocio (8002)
# - ml_service (8003)
# - dashboard (8080)
# - node_exporter (9100)
# - postgres_exporter (9187)
# - redis_exporter (9121)
# - prometheus (9090)
```

**2. Verificar mÃ©tricas en Prometheus:**
```bash
# Queries de ejemplo en http://localhost:9090/graph

# Ver servicios UP
up{job=~"agente_.*|ml_service|dashboard"}

# Request rate
rate(http_requests_total[5m])

# Error rate
rate(http_errors_total[5m])

# CPU usage
rate(container_cpu_usage_seconds_total[5m])
```

**3. Verificar dashboards en Grafana:**
```bash
# Abrir http://localhost:3000
# Login: admin/admin
# Ir a Dashboards > Browse > MiniMarket folder
# Abrir "System Overview"
# Debe mostrar datos en todos los panels (si servicios estÃ¡n corriendo)
```

**4. Verificar logs en Loki:**
```bash
# En Grafana, ir a Explore (Ã­cono de brÃºjula)
# Seleccionar datasource "Loki"
# Query de ejemplo: {job="agente_deposito"}
# Debe mostrar logs recientes del servicio
```

**5. Smoke test completo:**
```bash
# Script automatizado para verificar todo el stack
cd inventario-retail/observability

# Ejecutar smoke test
bash ../scripts/check_metrics_dashboard.sh http://localhost:9090 http://localhost:3000

# Esperado: todos los checks en verde
```

### Monitoreo de MÃ©tricas Clave

**KPIs del Sistema (Targets ETAPA 3):**
- âœ… **Uptime:** >99.9%
- âœ… **P95 Latency:** <300ms
- âœ… **Error Rate:** <0.5%
- âœ… **Cache Hit Rate:** >70%
- âœ… **OCR Timeout Rate:** <10/hora
- âœ… **ML Prediction Accuracy:** >90%

**Verificar KPIs actuales:**
```bash
# Request en Prometheus o ver en Dashboard "System Overview"

# Uptime Ãºltimos 7 dÃ­as
100 * (1 - (rate(up[7d] == 0) / rate(up[7d])))

# P95 Latency
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) * 1000

# Error Rate
100 * (rate(http_errors_total[5m]) / rate(http_requests_total[5m]))

# Cache Hit Rate
100 * (rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])))
```

### Runbooks de Operaciones

Consultar runbooks detallados para troubleshooting:

**1. Respuesta a Alertas:**
```bash
# Ver procedimientos para cada alerta
cat inventario-retail/observability/runbooks/RESPONDING_TO_ALERTS.md

# Incluye diagnÃ³stico y resoluciÃ³n paso a paso para:
# - ServiceDown, HighErrorRate, DatabaseDown
# - HighLatency, MemoryPressure, CPUHigh
# - StockCritico, OCRTimeoutSpike, MLModelDrift
# - Y todas las demÃ¡s alertas configuradas
```

**2. Troubleshooting de Dashboards:**
```bash
# Ver guÃ­a de problemas comunes
cat inventario-retail/observability/runbooks/DASHBOARD_TROUBLESHOOTING.md

# Incluye soluciones para:
# - Dashboard no muestra datos
# - Queries muy lentas
# - Grafana no carga
# - Datasource no conecta
# - MÃ©tricas desactualizadas
```

### Mantenimiento del Stack

**Limpieza de datos antiguos:**
```bash
# Prometheus retention configurado: 30 dÃ­as
# Loki retention configurado: 30 dÃ­as
# Ambos limpian automÃ¡ticamente datos antiguos

# Ver tamaÃ±o actual de datos
docker exec prometheus du -sh /prometheus
docker exec loki du -sh /loki

# Si es necesario, ajustar retention en configs:
# - observability/prometheus/prometheus.yml (--storage.tsdb.retention.time)
# - observability/loki/loki-config.yml (retention_period: 720h)
```

**Backup de configuraciones:**
```bash
# Backup de dashboards de Grafana
docker exec grafana tar czf /tmp/grafana-dashboards.tar.gz /etc/grafana/provisioning
docker cp grafana:/tmp/grafana-dashboards.tar.gz ./backups/

# Backup de configuraciones de Prometheus
docker exec prometheus tar czf /tmp/prometheus-config.tar.gz /etc/prometheus
docker cp prometheus:/tmp/prometheus-config.tar.gz ./backups/

# Los configs tambiÃ©n estÃ¡n en Git en inventario-retail/observability/
```

**ActualizaciÃ³n del stack:**
```bash
# Actualizar a versiones mÃ¡s recientes
cd inventario-retail/observability

# Editar docker-compose.observability.yml con nuevas versiones
# Ejemplo: prom/prometheus:v2.45.0 -> prom/prometheus:v2.47.0

# Pull de nuevas imÃ¡genes
docker-compose -f docker-compose.observability.yml pull

# Aplicar actualizaciones (con mÃ­nimo downtime)
docker-compose -f docker-compose.observability.yml up -d

# Verificar que todo funciona
docker-compose -f docker-compose.observability.yml ps
curl http://localhost:9090/-/healthy
curl http://localhost:3000/api/health
```

### Detener Stack de Observability

```bash
cd inventario-retail/observability

# Detener todos los componentes (mantiene volÃºmenes con datos)
docker-compose -f docker-compose.observability.yml down

# Detener y eliminar volÃºmenes (CUIDADO: borra todos los datos histÃ³ricos)
docker-compose -f docker-compose.observability.yml down -v
```

### Troubleshooting ComÃºn

**Prometheus no scrape targets:**
```bash
# Verificar que servicios estÃ¡n en la misma red Docker
docker network inspect inventario-retail_default | grep -E "(prometheus|agente)"

# Si no, agregar prometheus a la red correcta
docker network connect inventario-retail_default prometheus

# Reiniciar Prometheus
docker-compose -f docker-compose.observability.yml restart prometheus
```

**Grafana muestra "No data":**
```bash
# Verificar datasource Prometheus
# En Grafana: Configuration > Data Sources > Prometheus
# URL debe ser: http://prometheus:9090 (nombre del contenedor, no localhost)
# Click en "Save & Test" - debe mostrar "Data source is working"

# Si falla, verificar que Grafana y Prometheus estÃ¡n en la misma red
docker network connect inventario-retail_default grafana
docker-compose -f docker-compose.observability.yml restart grafana
```

**Alertas no llegan a Slack:**
```bash
# Verificar webhook URL en alertmanager.yml
docker exec alertmanager cat /etc/alertmanager/alertmanager.yml | grep api_url

# Verificar logs de Alertmanager
docker logs alertmanager | grep -i "slack\|error"

# Test manual de notificaciÃ³n (ver secciÃ³n "ConfiguraciÃ³n de Alertmanager")
```

**Para mÃ¡s detalles, consultar:**
- `observability/runbooks/RESPONDING_TO_ALERTS.md`
- `observability/runbooks/DASHBOARD_TROUBLESHOOTING.md`

---

## ğŸ”’ Seguridad - TLS y Comunicaciones Seguras

### ConfiguraciÃ³n de TLS para Prometheus y Alertmanager

A partir de ETAPA 3, se implementÃ³ comunicaciÃ³n segura entre Prometheus y Alertmanager usando TLS con autenticaciÃ³n mutua.

**Certificados:**
```bash
# Los certificados se encuentran en:
inventario-retail/observability/prometheus/tls/
â”œâ”€â”€ ca.crt                    # Certificate Authority
â”œâ”€â”€ ca.key                    # Private key del CA
â”œâ”€â”€ prometheus.crt            # Certificado de cliente (Prometheus)
â”œâ”€â”€ prometheus.key            # Private key de Prometheus
â”œâ”€â”€ alertmanager.crt          # Certificado de servidor (Alertmanager)
â””â”€â”€ alertmanager.key          # Private key de Alertmanager

# Validez: 365 dÃ­as desde la generaciÃ³n
# Generados con: OpenSSL 3.0+ | RSA 4096-bit | TLS 1.2+
```

**GeneraciÃ³n de nuevos certificados:**
```bash
# Regenerar certificados (Ãºtil para renovaciÃ³n antes de expirar)
cd inventario-retail/observability/prometheus/tls

# Hacer backup de certificados actuales
mv ca.crt ca.crt.bak
mv ca.key ca.key.bak
mv prometheus.* prometheus.bak/
mv alertmanager.* alertmanager.bak/

# Ejecutar script de generaciÃ³n
./generate_certs.sh

# Verificar nuevos certificados
openssl x509 -in prometheus.crt -text -noout | grep "Not Before\|Not After"
```

**VerificaciÃ³n de conectividad TLS:**
```bash
# Verificar que Prometheus puede conectar a Alertmanager con TLS
docker exec prometheus curl --cacert /etc/prometheus/tls/ca.crt \
  --cert /etc/prometheus/tls/prometheus.crt \
  --key /etc/prometheus/tls/prometheus.key \
  https://alertmanager:9093/api/v2/status

# Esperado: JSON con status de Alertmanager
```

**DocumentaciÃ³n completa:**
```bash
# Ver guÃ­a detallada de TLS setup
cat security/TLS_SETUP.md

# Incluye:
# - Arquitectura de seguridad
# - Procedimientos de renovaciÃ³n
# - Troubleshooting de certificados
# - Mejores prÃ¡cticas
```

---

## ğŸ” EncriptaciÃ³n de Datos - Datos en Reposo

### Cifrado de Datos Sensibles en PostgreSQL

A partir de ETAPA 3, se implementÃ³ cifrado AES-256-CBC para datos sensibles usando la extensiÃ³n pgcrypto de PostgreSQL.

**Datos cifrados:**
```sql
-- Tabla: system_config
- api_key_encrypted
- jwt_secret_encrypted
- slack_webhook_encrypted

-- Tabla: productos
- costo_adquisicion_encrypted
- precio_sugerido_encrypted
```

**Aplicar migraciÃ³n de cifrado:**
```bash
# La migraciÃ³n 004_add_encryption.sql debe ser aplicada una sola vez
# Verificar si ya fue aplicada:

docker exec inventario_retail_db psql -U postgres inventario_retail -c \
  "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='pgcrypto')"
# Resultado: t (true) = ya aplicada | f (false) = no aplicada

# Si no estÃ¡ aplicada:
docker exec inventario_retail_db psql -U postgres inventario_retail \
  -f /docker-entrypoint-initdb.d/004_add_encryption.sql

# Verificar funciones de cifrado
docker exec inventario_retail_db psql -U postgres inventario_retail -c \
  "\df encrypt_data"
```

**ConfiguraciÃ³n de la clave maestra:**
```bash
# En .env.production, establecer clave de 32 bytes (64 caracteres hex)
DATABASE_ENCRYPTION_KEY=0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef

# IMPORTANTE:
# - Usar clave fuerte y aleatoria
# - NO compartir esta clave en repositorio
# - Guardar copia segura en bÃ³veda de secretos
# - Rotar cada 90 dÃ­as (ver procedimiento abajo)
```

**Uso de funciones de cifrado:**
```sql
-- Cifrar datos
UPDATE system_config SET 
  api_key_encrypted = encrypt_data(api_key, current_setting('DATABASE_ENCRYPTION_KEY'))
WHERE id = 1;

-- Descifrar datos
SELECT decrypt_data(api_key_encrypted, current_setting('DATABASE_ENCRYPTION_KEY'))
FROM system_config WHERE id = 1;

-- AuditorÃ­a de acceso
SELECT * FROM encrypted_data_access_log 
ORDER BY accessed_at DESC 
LIMIT 10;
```

**RotaciÃ³n de claves de cifrado (Procedimiento):**
```bash
# 1. Generar nueva clave maestra
NEW_KEY=<generar-nueva-clave-32-bytes>

# 2. En production, ejecutar:
docker exec inventario_retail_db psql -U postgres inventario_retail << EOF
BEGIN;

-- Re-cifrar todos los datos con nueva clave
UPDATE system_config SET
  api_key_encrypted = encrypt_data(
    decrypt_data(api_key_encrypted, current_setting('old_key')), 
    '$NEW_KEY'
  );

COMMIT;
EOF

# 3. Actualizar DATABASE_ENCRYPTION_KEY en .env.production
# 4. Reiniciar servicios que usan la BD
```

**VerificaciÃ³n de integridad:**
```bash
# Verificar que todos los datos se pueden descifrar
docker exec inventario_retail_db psql -U postgres inventario_retail -c \
  "SELECT COUNT(*) FROM system_config WHERE decrypt_data(api_key_encrypted, current_setting('DATABASE_ENCRYPTION_KEY')) IS NULL"
# Esperado: 0 (ninguno nulo)
```

**Rollback (en caso de necesidad):**
```bash
# Si necesitas revertir la migraciÃ³n de cifrado:
docker exec inventario_retail_db psql -U postgres inventario_retail \
  -f /docker-entrypoint-initdb.d/004_add_encryption_rollback.sql

# ADVERTENCIA: esto elimina las columnas cifradas y las funciones
# Ejecutar solo si es absolutamente necesario
```

**DocumentaciÃ³n completa:**
```bash
# Ver guÃ­a detallada de encriptaciÃ³n
cat security/DATA_ENCRYPTION.md

# Incluye:
# - Estrategia de encriptaciÃ³n
# - Ejemplos de uso (SQL y Python)
# - AnÃ¡lisis de performance
# - GestiÃ³n de claves
# - Compliance y auditorÃ­a
```

---

## ğŸ“Š Performance - Load Testing

### Suite de Load Testing con k6

A partir de ETAPA 3, se implementÃ³ suite completa de load testing automatizado con k6 para validar performance de todos los endpoints crÃ­ticos.

**UbicaciÃ³n de scripts:**
```bash
inventario-retail/scripts/load_testing/
â”œâ”€â”€ test-health.js           # Baseline: health check (P95<100ms)
â”œâ”€â”€ test-inventory-read.js   # Lectura: GET operations (P95<300ms)
â”œâ”€â”€ test-inventory-write.js  # Escritura: POST operations (P95<500ms)
â”œâ”€â”€ test-metrics.js          # MÃ©tricas: Prometheus scraping (P95<200ms)
â”œâ”€â”€ run-all.sh               # Orquestador de suite completa
â””â”€â”€ results/                 # Directorio de resultados
```

**Requisitos previos:**
```bash
# Instalar k6
sudo apt install k6

# Verificar instalaciÃ³n
k6 version
```

**Ejecutar tests individuales:**
```bash
cd inventario-retail/scripts/load_testing

# Test de health check
k6 run test-health.js

# Test de lectura (requiere API key)
k6 run -e BASE_URL=http://localhost:8080 \
       -e API_KEY=your-api-key \
       test-inventory-read.js

# Test de escritura (CUIDADO: crea datos de prueba)
k6 run -e BASE_URL=http://localhost:8080 \
       -e API_KEY=your-api-key \
       test-inventory-write.js

# Test de mÃ©tricas
k6 run -e BASE_URL=http://localhost:8080 \
       -e API_KEY=your-api-key \
       test-metrics.js
```

**Ejecutar suite completa:**
```bash
cd inventario-retail/scripts/load_testing

# EjecuciÃ³n bÃ¡sica (omite write tests por defecto)
./run-all.sh

# Con parÃ¡metros personalizados
BASE_URL=https://staging.yourdomain.com \
API_KEY=staging-key \
SKIP_WRITE_TESTS=true \
./run-all.sh

# Continuar aunque fallen algunos tests
CONTINUE_ON_FAILURE=true ./run-all.sh
```

**Umbrales de Performance (SLOs):**

| Endpoint | MÃ©trica | Target | CrÃ­tico |
|----------|---------|--------|---------|
| `/health` | P95 Latency | <100ms | <200ms |
| `/health` | Error Rate | <0.1% | <1% |
| `/api/inventory` | P95 Latency | <300ms | <500ms |
| `/api/inventory` | Error Rate | <0.5% | <2% |
| `/metrics` | P95 Latency | <200ms | <400ms |
| `/metrics` | Error Rate | <0.1% | <1% |

**AnÃ¡lisis de resultados:**
```bash
# Ver resultados mÃ¡s recientes
cat results/consolidated-report-*.txt

# AnÃ¡lisis JSON
cat results/health-check-summary.json | jq '.metrics.http_req_duration'

# Latencia por percentil
cat results/health-check-summary.json | jq '.metrics.http_req_duration.values | {min, med, "p(95)", "p(99)", max}'
```

**Pre-deployment gate:**
```bash
# Ejecutar como verificaciÃ³n antes de deploy
SKIP_WRITE_TESTS=true ./run-all.sh

# Si algÃºn threshold falla, abortar deployment
if [ $? -ne 0 ]; then
  echo "âŒ Performance baseline no cumplido. Abortando deployment."
  exit 1
fi
```

**DocumentaciÃ³n completa:**
```bash
# Ver guÃ­a detallada de load testing
cat scripts/load_testing/LOAD_TESTING.md

# Incluye:
# - InstalaciÃ³n de k6
# - DescripciÃ³n de cada test
# - IntegraciÃ³n CI/CD
# - Troubleshooting
# - Mejores prÃ¡cticas
```

---

## ğŸ”„ Backup y Restore

### Backup AutomÃ¡tico
```bash
# Backup manual
./scripts/deploy.sh --backup

# Programar backup diario (cron)
0 2 * * * /path/to/inventario-retail/scripts/deploy.sh --backup
```

### Restore
```bash
# Restaurar desde backup
./scripts/deploy.sh --restore backups/backup_20250101_020000.sql
```

---

## ğŸš¨ Troubleshooting

### Problemas Comunes

**Servicios no inician**:
```bash
# Ver logs de error
docker-compose -f docker-compose.production.yml logs

# Verificar puertos ocupados
sudo netstat -tulpn | grep :8001
```

**Base de datos no conecta**:
```bash
# Verificar PostgreSQL
docker exec -it inventario_retail_db pg_isready -U postgres

# Ver logs de DB
docker logs inventario_retail_db
```

**JWT tokens invÃ¡lidos**:
```bash
# Verificar JWT_SECRET_KEY en .env.production
# Regenerar tokens con nuevo secret
```

### Problemas de TLS/Certificados

**Certificados expirados:**
```bash
# Verificar validez de certificados
openssl x509 -in observability/prometheus/tls/prometheus.crt -text -noout | grep "Not After"

# Si estÃ¡n a punto de expirar (< 30 dÃ­as):
cd observability/prometheus/tls
./generate_certs.sh  # Generar nuevos certificados

# Reiniciar servicios
docker-compose -f ../docker-compose.observability.yml restart prometheus alertmanager
```

**Error de certificado en Prometheus:**
```bash
# Verificar que Prometheus puede conectar a Alertmanager con TLS
docker exec prometheus curl --cacert /etc/prometheus/tls/ca.crt \
  --cert /etc/prometheus/tls/prometheus.crt \
  --key /etc/prometheus/tls/prometheus.key \
  https://alertmanager:9093/api/v2/status

# Si falla verificar:
# 1. Archivos de certificados estÃ¡n en lugar correcto
# 2. Permisos de archivos (.key en 600)
# 3. Nombres de hosts en configuraciÃ³n coinciden con CN en certificados

docker exec prometheus ls -la /etc/prometheus/tls/
```

**Error: "certificate verify failed":**
```bash
# Verificar que CA.crt es vÃ¡lido y accesible
docker exec prometheus openssl verify -CAfile /etc/prometheus/tls/ca.crt \
  /etc/prometheus/tls/prometheus.crt

# Esperado: "OK"
# Si falla, regenerar certificados:
cd observability/prometheus/tls && ./generate_certs.sh
```

### Problemas de EncriptaciÃ³n

**Error: "column does not exist api_key_encrypted":**
```bash
# La migraciÃ³n de cifrado no ha sido aplicada
# Verificar si existe la extensiÃ³n pgcrypto:
docker exec inventario_retail_db psql -U postgres inventario_retail -c \
  "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='pgcrypto')"

# Si false (f), aplicar migraciÃ³n:
docker exec inventario_retail_db psql -U postgres inventario_retail \
  -f /docker-entrypoint-initdb.d/004_add_encryption.sql

# Reiniciar servicios que usan BD
docker-compose -f docker-compose.production.yml restart agente-deposito agente-negocio
```

**Error: "Failed to decrypt data":**
```bash
# La clave DATABASE_ENCRYPTION_KEY en .env es incorrecta
# Causas:
# 1. Clave no seteada (verificar: echo $DATABASE_ENCRYPTION_KEY)
# 2. Clave con formato incorrecto (debe ser 64 caracteres hex)
# 3. Clave cambiÃ³ despuÃ©s de cifrar datos (imposible recuperar)

# Verificar que estÃ¡ bien seteada:
docker exec -e DATABASE_ENCRYPTION_KEY=$DATABASE_ENCRYPTION_KEY \
  inventario_retail_db psql -U postgres inventario_retail -c \
  "SELECT decrypt_data(api_key_encrypted, current_setting('DATABASE_ENCRYPTION_KEY')) FROM system_config LIMIT 1"

# Si devuelve NULL, la clave es incorrecta
```

**Overhead de performance por cifrado:**
```bash
# EncriptaciÃ³n tiene overhead ~60-66%
# Si performance degrada mucho:

# OpciÃ³n 1: Reducir datos cifrados (cifrar solo lo crÃ­tico)
# OpciÃ³n 2: Agregar Ã­ndices en columnas buscadas
# OpciÃ³n 3: Cache mÃ¡s agresivo en Redis

# Ver anÃ¡lisis detallado:
cat security/DATA_ENCRYPTION.md
```

### Problemas de Load Testing

**Error: "k6 no encontrado":**
```bash
# Instalar k6
sudo apt update && sudo apt install k6

# Verificar
k6 version
```

**Error: "Connection refused":**
```bash
# Servicio no estÃ¡ respondiendo
# Verificar que estÃ¡ up:
curl http://localhost:8080/health

# Si no responde:
docker-compose -f docker-compose.production.yml ps

# Reiniciar si es necesario:
docker-compose -f docker-compose.production.yml restart dashboard
```

**Error: "401 Unauthorized" en tests:**
```bash
# API key invÃ¡lida o no seteada
# Verificar que se pasa correctamente:
k6 run -e API_KEY=your-api-key-here test-health.js

# Verificar que API key es correcta:
grep DASHBOARD_API_KEY .env.production
echo $DASHBOARD_API_KEY
```

**Tests fallan por umbrales de performance:**
```bash
# Los SLOs no se cumplen (ej: P95 > 300ms)

# Causas comunes:
# 1. Base de datos lenta: revisar queries, agregar Ã­ndices
# 2. CPU/memoria limitada: escalar recursos
# 3. Network latency: usar misma regiÃ³n/AZ
# 4. Logging excesivo: reducir nivel de log

# Soluciones:
# - Analizar resultados JSON:
cat results/health-check-summary.json | jq '.metrics.http_req_duration'

# - Reducir carga del test temporalmente:
k6 run --vus 25 --duration 2m test-health.js

# - Revisar logs mientras corre test:
docker-compose -f docker-compose.production.yml logs -f dashboard &
k6 run test-health.js
```

**Datos de prueba acumulÃ¡ndose:**
```bash
# El test test-inventory-write.js crea productos ficticios
# Limpiar despuÃ©s de tests:
docker exec -it inventario_retail_db psql -U postgres inventario_retail << EOF
DELETE FROM productos WHERE sku LIKE 'TEST-SKU-%';
COMMIT;
EOF
```

### Logs de Debug
```bash
# Habilitar debug logs
echo "LOG_LEVEL=DEBUG" >> .env.production
./scripts/deploy.sh --restart
```

---

## ğŸ“ˆ Escalado

### Horizontal Scaling
```bash
# Escalar servicios especÃ­ficos
docker-compose -f docker-compose.production.yml up -d --scale agente-deposito=3
docker-compose -f docker-compose.production.yml up -d --scale agente-negocio=2
```

### Load Balancer
- Nginx configurado untuk load balancing automÃ¡tico
- Health checks y failover incluidos

---

## ğŸ†™ Actualizaciones

### Rolling Updates
```bash
# Actualizar imagen especÃ­fica
docker-compose -f docker-compose.production.yml pull agente-deposito
docker-compose -f docker-compose.production.yml up -d --no-deps agente-deposito

# ActualizaciÃ³n completa
git pull
./scripts/deploy.sh --build
./scripts/deploy.sh --restart
```

---

## ğŸ“ Contacto y Soporte

- **DocumentaciÃ³n tÃ©cnica**: Ver archivos en `/docs/`
- **APIs**: Swagger UI disponible en `/docs` de cada servicio
- **Logs**: Revisar `./logs/` para troubleshooting

**Estado del sistema**: âœ… Listo para producciÃ³n